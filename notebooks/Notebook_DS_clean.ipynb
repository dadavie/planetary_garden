{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca09404",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978210d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbef7da",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - variables - functions - calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162368e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_nam_list = ['cld', 'dtr', 'frs', 'pet', 'pre', 'tmn', 'tmp', 'tmx', 'vap', 'wet']\n",
    "fold_n = '/Users/davidschildberger/03_LeWagon_Datasets/CRU_raw_data_2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d89567",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_filename(feat_name):\n",
    "    fi_n = os.listdir(fold_n)\n",
    "    fi_n.remove('.DS_Store')\n",
    "    for i in fi_n: \n",
    "        if(feat_name in i) : \n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52acbb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def open_netcdf(fname):\n",
    "    with gzip.open((fold_n+fname), 'rb') as f:\n",
    "        tmp = tempfile.NamedTemporaryFile(delete=False)\n",
    "        shutil.copyfileobj(f, tmp)\n",
    "\n",
    "        f.close()\n",
    "        tmp.close()\n",
    "        \n",
    "        data = netCDF4.Dataset(tmp.name)\n",
    "        os.unlink(tmp.name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085c54f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Bio 1 / Annual Mean Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b77441fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_1(year):\n",
    "    val = 'tmp'\n",
    "    data = open_netcdf(get_filename(val))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    d = data.variables[val][year_in_month:year_in_month+12,:,:].data.mean(axis=0)\n",
    "    d[d > 99999] = np.nan\n",
    "    res = np.flip(d,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5394ad7",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Bio 2 / Mean Diurnal Range (Mean of monthly (max temp - min temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bf5fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_2(year):\n",
    "    data_tmn = open_netcdf(get_filename('tmn'))\n",
    "    data_tmx = open_netcdf(get_filename('tmx'))\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_min = data_tmn.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_max = data_tmx.variables['tmx'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_min[t_min > 255] = np.nan\n",
    "    t_max[t_max > 255] = np.nan\n",
    "    d = t_max - t_min\n",
    "    d = d.mean(axis=0)\n",
    "    d[d > 99999] = np.nan\n",
    "    res = np.flip(d,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a312b29f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 3 / Isothermality (BIO2/BIO7) (Ã—100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f782271",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_3(year):\n",
    "    val = bio_2(year)/bio_7(year)\n",
    "    val[val > 99999] = np.nan\n",
    "    res = np.around(val, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476702a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 4 / Temperature Seasonality (standard deviation Ã—100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a2a14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_4(year):\n",
    "    data = open_netcdf(get_filename('tmp'))\n",
    "\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_mp = data.variables['tmp'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_mp[t_mp > 99999] = np.nan\n",
    "    res = np.std(t_mp, axis=0)\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda023cc",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 5 / Max Temperature of Warmest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8be14",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_5(year):\n",
    "    data = open_netcdf(get_filename('tmx'))\n",
    "\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_max = data.variables['tmx'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_max[t_max > 99999] = np.nan\n",
    "    res = np.max(t_max, axis=0)\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48e94f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 6 / Min Temperature of Coldest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c8a68",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_6(year):\n",
    "    data = open_netcdf(get_filename('tmn'))\n",
    "\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_min = data.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_min[t_min > 99999] = np.nan\n",
    "    res = np.min(t_min, axis=0)\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797eef87",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 7 / Temperature Annual Range (BIO5-BIO6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c148b78f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_7(year):\n",
    "    rang_temp = bio_5(1980)-bio_6(1980)\n",
    "    rang_temp[rang_temp > 99999] = np.nan\n",
    "    res = np.around(rang_temp, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fdc18",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 8 / Mean Temperature of Wettest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984278ee",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_8(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80af8d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 9 / Mean Temperature of Driest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea15e34b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_9(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a6665",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO10 / Mean Temperature of Warmest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4181e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_10(year):\n",
    "    data_wet = open_netcdf(get_filename('tmx'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmx'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4269665",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 11 / Mean Temperature of Coldest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01029a11",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_11(year):\n",
    "    data_wet = open_netcdf(get_filename('tmn'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b5d0b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 12 / Annual Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0ad56",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_12(year):\n",
    "    data_pre = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_pre.variables['pre'][year_in_month:year_in_month+12,:,:].data\n",
    "    temp_wet[temp_wet > 99999] = np.nan\n",
    "    temp_wet = np.sum(temp_wet, axis=0)\n",
    "    res = np.flip(temp_wet,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef7f99",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 13 / Precipitation of Wettest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633841aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_13(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    max_ind = np.argmax(temp_wet, axis=0)\n",
    "        \n",
    "    res = np.choose(max_ind, data_tmp.variables['pre'][year_in_month:year_in_month+12,:,:].data)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f344cf9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 14 / Precipitation of Driest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b8754",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_14(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    min_ind = np.argmin(temp_wet, axis=0)\n",
    "        \n",
    "    res = np.choose(min_ind, data_tmp.variables['pre'][year_in_month:year_in_month+12,:,:].data)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46dc804",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 15 / Precipitation Seasonality (Coefficient of Variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf2213a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_15(year):\n",
    "    val = 'pre'\n",
    "    data = open_netcdf(get_filename(val))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    d = data.variables[val][year_in_month:year_in_month+12,:,:].data\n",
    "    d[d > 99999] = np.nan\n",
    "    cv = lambda x: np.std(d, ddof=1, axis=0) / np.mean(d, axis=0) * 100\n",
    "    d = cv(d)\n",
    "    res = np.flip(d,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcba65",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 16 / Precipitation of Wettest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2c679",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_16(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42cb832",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 17 / Precipitation of Driest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357150ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_17(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11bffc8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 18 / Precipitation of Warmest Quarter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5599c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_18(year):\n",
    "    data_wet = open_netcdf(get_filename('tmp'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmp'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecec2d86",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO19 / Precipitation of Coldest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de967e57",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_19(year):\n",
    "    data_wet = open_netcdf(get_filename('tmn'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc8515",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - create and save files for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e4d8ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_and_save_bioclim():\n",
    "    for i in range(120,121):\n",
    "        st = 1901+i\n",
    "        os.makedirs(f\"../raw_data/bioclim/{st}\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_1.csv\", \n",
    "                   bio_1(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_2.csv\", \n",
    "                   bio_2(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_3.csv\", \n",
    "                   bio_3(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_4.csv\", \n",
    "                   bio_4(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_5.csv\", \n",
    "                   bio_5(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_6.csv\", \n",
    "                   bio_6(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_7.csv\", \n",
    "                   bio_7(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_8.csv\", \n",
    "                   bio_8(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_9.csv\", \n",
    "                   bio_9(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_10.csv\", \n",
    "                   bio_10(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_11.csv\", \n",
    "                   bio_11(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_12.csv\", \n",
    "                   bio_12(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_13.csv\", \n",
    "                   bio_13(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_14.csv\", \n",
    "                   bio_14(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_15.csv\", \n",
    "                   bio_15(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_16.csv\", \n",
    "                   bio_16(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_17.csv\", \n",
    "                   bio_17(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_18.csv\", \n",
    "                   bio_18(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_19.csv\", \n",
    "                   bio_19(st), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc484e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - read out all years and create big .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88195a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_csv_store_npy():\n",
    "    all_dat = []\n",
    "    for j in range(1901,2022):\n",
    "        print(j)\n",
    "        path = f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{j}/\"\n",
    "        #fi_n = os.listdir(path)\n",
    "        my_data = []\n",
    "        for i in range(19):\n",
    "            my_data.append(np.loadtxt(path+f\"bio_{i+1}.csv\", delimiter=\",\"))\n",
    "        all_dat.append(my_data)\n",
    "        \n",
    "    with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim_np/Bioclim.npy\", 'wb') as f:\n",
    "        np.save(f, np.array(all_dat))\n",
    "    return np.array(all_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d7ccf",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - Hist Clim for all exising lon/lat vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d396d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_all_climate_lon_lat():\n",
    "    \n",
    "    path = f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim_np/\"\n",
    "    filen = 'bioclim_upd.npy'\n",
    "    bioclim = np.load(path+filen)\n",
    "    \n",
    "    li_hist_df = []\n",
    "    for g in range(121):\n",
    "        li_clim = []\n",
    "        li_lon_lat_years = []\n",
    "        li_lon_lat = []\n",
    "        li_lon_lon = []\n",
    "        for i in range(360):\n",
    "            for j in range(720):\n",
    "                li_temp = []\n",
    "                for k in range(19):\n",
    "                    li_temp.append(bioclim[g,k,i,j])\n",
    "                li_lon_lat_years.append(f\"{g}\")\n",
    "                li_lon_lat.append(f\"{i}\")\n",
    "                li_lon_lon.append(f\"{j}\")\n",
    "                li_clim.append(li_temp)\n",
    "        aa = np.stack((np.array(li_lon_lat_years), np.array(li_lon_lat), np.array(li_lon_lon)))\n",
    "        aa = np.transpose(aa)\n",
    "        cc = np.array(li_clim)\n",
    "        uu = np.hstack((aa, cc))\n",
    "        xx = pd.DataFrame(uu)\n",
    "        xx = xx[xx[3].str.contains(\"nan\")==False]\n",
    "        li_hist_df.append(xx.to_numpy())\n",
    "    with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/world_history_bioclim_allLatLon_upd.npy\", 'wb') as f:\n",
    "        np.save(f, d)    \n",
    "    return np.array(li_hist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa4d3c7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Soilgrid - for all exising lon/lat vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ad2019",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_all_climate_soil_grid_lon_lat():\n",
    "    path = f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim_np/\"\n",
    "    filen = 'bioclim_upd.npy'\n",
    "    bioclim = np.load(path+filen)\n",
    "    data = np.load(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/soil_data.npy\")\n",
    "    \n",
    "    li_clim = []\n",
    "    li_lon_lat = []\n",
    "    li_lon_lon = []\n",
    "    for i in range(360):\n",
    "        #print(i)\n",
    "        for j in range(720):\n",
    "            li_temp = []\n",
    "            for k in range(19):\n",
    "                li_temp.append(bioclim[0,k,i,j])\n",
    "            for u in range(60):\n",
    "                li_temp.append(data[k,i,j])\n",
    "            \n",
    "            li_lon_lat.append(f\"{i}\")\n",
    "            li_lon_lon.append(f\"{j}\")\n",
    "            li_clim.append(li_temp)\n",
    "                \n",
    "    aa = np.stack((np.array(li_lon_lat), np.array(li_lon_lon)))\n",
    "    aa = np.transpose(aa)\n",
    "    cc = np.array(li_clim)\n",
    "    uu = np.hstack((aa, cc))\n",
    "    xx = pd.DataFrame(uu)\n",
    "    xx = xx[xx[3].str.contains(\"nan\")==False]\n",
    "    xx.columns = [np.arange(0,81)]\n",
    "    xx = xx.drop(xx.columns[np.arange(2,21)],axis = 1)\n",
    "    xx.columns = [np.arange(0,62)]\n",
    "    with open(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/world_soilgrid_allLatLon_withzeros_upd.npy\", 'wb') as f:\n",
    "        np.save(f, xx)\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f1ace",
   "metadata": {},
   "source": [
    "# Bioclim - Hist Clim and Soil Data for all exising lon/lat vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bb86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_histclim_soilgrid_lon_lat():\n",
    "    path = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/'\n",
    "    file_c = 'world_history_bioclim_allLatLon_upd.npy'\n",
    "    file_s = 'world_soilgrid_allLatLon_withzeros_upd.npy'\n",
    "    cl_data = np.load(path+file_c, allow_pickle=True)\n",
    "    sg_data = np.load(path+file_s, allow_pickle=True)\n",
    "\n",
    "    np.concatenate((cl_data[0,:,:], sg_data), axis=1).shape\n",
    "\n",
    "    lit = []\n",
    "    for i in range(len(cl_data)):\n",
    "        lit.append(np.concatenate((cl_data[i,:,:], sg_data[:,2:]), axis=1))\n",
    "    lit = np.array(lit)\n",
    "\n",
    "    with open(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/clim_hist_soil_overall.npy\", 'wb') as f:\n",
    "        np.save(f, lit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbee72f",
   "metadata": {},
   "source": [
    "# Plants - Retrieve Bioclim and Soilgrid Data for plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bioclim_from_plants_from_overall_file():\n",
    "    \n",
    "    df = pd.read_csv(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/data_clean_5_continent_Animal_plants.csv\", on_bad_lines='skip')\n",
    "    df = df[(df['year']>=1901) & (df['year']<=2021)]\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    path = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/'\n",
    "    filen = 'clim_hist_soil_overall.npy'\n",
    "    ov_data = np.load(path+filen, allow_pickle=True)\n",
    "    \n",
    "    ## column names bioclim\n",
    "    b_col =['b1', 'b2', 'b3', 'b4', 'b5','b6','b7','b8','b9','b10','b11','b12','b13','b14','b15','b16','b17','b18','b19']\n",
    "    \n",
    "    ## column names soilgrid\n",
    "    numb = (np.arange(1,61))\n",
    "    s = ('sg')\n",
    "    sg_col =[]\n",
    "    for item in numb:\n",
    "        sg_col.append(s+str(item))\n",
    "        \n",
    "    coln = b_col + sg_col\n",
    "    \n",
    "    df_feat = pd.DataFrame(columns=[coln], index = [np.arange(0,len(df))])\n",
    "    \n",
    "    for i in range(len(df)):  \n",
    "        lat = df.loc[i, 'decimalLatitude']\n",
    "        lon = df.loc[i, 'decimalLongitude']\n",
    "        year = int(df.loc[i, 'year'])\n",
    "        \n",
    "        c_lat = int(round(np.interp(lat, [-90, 90], [360, 0])))  # check order of values here\n",
    "        c_lon = int(round(np.interp(lon, [-180, 180], [1, 719])))\n",
    "\n",
    "        temp_df = pd.DataFrame(ov_data[year-1901, :, :])\n",
    "        temp_df = temp_df[(temp_df[1]==str(c_lat)) & (temp_df[2]==str(c_lon))].iloc[:,3:]\n",
    "        temp_df.columns = coln\n",
    "        if not temp_df.empty:\n",
    "            temp_df = temp_df.set_index([[i]])\n",
    "            df_feat.iloc[i,:]=temp_df\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    #df.dropna(inplace=True)\n",
    "    df_feat.to_csv(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/plants_bioclim_soil_upd.csv\")\n",
    "    return df_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5211263",
   "metadata": {},
   "source": [
    "# Future Clim - Retrieve Bioclim and Soilgrid Data for plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future_clim():\n",
    "    latr = np.arange(-90,90, 0.5)\n",
    "    lonr = np.arange(-180,180, 0.5)\n",
    "\n",
    "    fi_n = sorted(os.listdir(fold_n))\n",
    "    fi_n.remove('.DS_Store')\n",
    "    fold_n = ('/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/WorldClim_future/')\n",
    "\n",
    "    overall= []\n",
    "    for fn in fi_n:\n",
    "        print(fn)\n",
    "        src = rasterio.open(fold_n+fn)\n",
    "        all_bio = []\n",
    "\n",
    "        lili = []\n",
    "        for i in range(360):\n",
    "            print(i)\n",
    "            for j in range(720):\n",
    "                for val in src.sample([(lonr[j], latr[i])]): \n",
    "                    lili.append(val)\n",
    "\n",
    "        a = np.array(lili)\n",
    "        b = a.transpose(1,0)\n",
    "        dada = []\n",
    "        for i in range(19):\n",
    "            z = b[i].reshape(360,720)\n",
    "            z = np.flip(z, axis=0)\n",
    "            dada.append(z)\n",
    "        overall.append(np.array(dada))\n",
    "    with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/WorldClim_future_np/overall_future_clim.npy\", 'wb') as f:\n",
    "        np.save(f, np.array(overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbccfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_climate_lon_lat():\n",
    "    \n",
    "    data_fc = np.load(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/WorldClim_future_np/overall_future_clim.npy\")\n",
    "    \n",
    "    li_hist_df = []\n",
    "    for g in range(16):\n",
    "        li_clim = []\n",
    "        li_lon_lat_years = []\n",
    "        li_lon_lat = []\n",
    "        li_lon_lon = []\n",
    "        for i in range(360):\n",
    "            for j in range(720):\n",
    "                li_temp = []\n",
    "                for k in range(19):\n",
    "                    li_temp.append(data_fc[g,k,i,j])\n",
    "                li_lon_lat_years.append(f\"{g}\")\n",
    "                li_lon_lat.append(f\"{i}\")\n",
    "                li_lon_lon.append(f\"{j}\")\n",
    "                li_clim.append(li_temp)\n",
    "        aa = np.stack((np.array(li_lon_lat_years), np.array(li_lon_lat), np.array(li_lon_lon)))\n",
    "        aa = np.transpose(aa)\n",
    "        cc = np.array(li_clim)\n",
    "        uu = np.hstack((aa, cc))\n",
    "        xx = pd.DataFrame(uu)\n",
    "        xx = xx[xx[3].str.contains(\"nan\")==False]\n",
    "        li_hist_df.append(xx.to_numpy())\n",
    "        \n",
    "    with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/overall_future_clim_allLatLon_upd.npy\", 'wb') as f:\n",
    "        np.save(f, d)\n",
    "    return np.array(li_hist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e7566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_future_clim_with_soil():\n",
    "    path = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/'\n",
    "    file_cl = 'overall_future_clim_allLatLon_upd.npy'\n",
    "    file_s = 'world_soilgrid_allLatLon_withzeros_upd.npy'\n",
    "    cl_fut = np.load(path+file_cl, allow_pickle=True)\n",
    "    sg_data = np.load(path+file_s, allow_pickle=True)\n",
    "    \n",
    "    ## column names soilgrid\n",
    "    numb = (np.arange(1,61))\n",
    "    s = ('sg')\n",
    "    sg_col =[]\n",
    "    for item in numb:\n",
    "        sg_col.append(s+str(item))\n",
    "        \n",
    "    sdf = pd.DataFrame(sg_data)\n",
    "    sdf = sdf.astype(float)\n",
    "    sg = [0,1]\n",
    "    col = sg + sg_col\n",
    "    sdf.columns=col\n",
    "    sdf = sdf.astype({0:'int', 1:'int'})\n",
    "    \n",
    "    li_df = []\n",
    "    for i in range(len(cl_fut)):\n",
    "        ## column names bioclim\n",
    "        b_col =['b1', 'b2', 'b3', 'b4', 'b5','b6','b7','b8','b9','b10','b11','b12','b13','b14','b15','b16','b17','b18','b19']\n",
    "        col2 = sg + b_col\n",
    "        cldf = pd.DataFrame(cl_fut[i])\n",
    "        cldf = cldf.astype(float)\n",
    "        cldf = cldf.drop(columns=0)\n",
    "        cldf.columns = col2\n",
    "        cldf = cldf.astype({0:'int', 1:'int'})\n",
    "\n",
    "        ## merge df\n",
    "        new_df = pd.merge(cldf, sdf,  how='left', left_on=[0,1], right_on = [0,1])\n",
    "        new_df = new_df.dropna()\n",
    "        li_df.append(new_df.to_numpy())\n",
    "        \n",
    "    with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/future_clim_soilgr.npy\", 'wb') as f:\n",
    "        np.save(f, np.array(li_df))\n",
    "    return np.array(li_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d2f9e",
   "metadata": {},
   "source": [
    "# Image scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546db2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_to_scrap():\n",
    "    ## get plant - multimedia data\n",
    "    df_m = pd.read_csv('/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/multimedia.txt', sep='\\t', index_col='gbifID')\n",
    "    df_m = df_m[['identifier']]\n",
    "    ## get plant - info\n",
    "    df_i = pd.read_csv(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/data_inkl_bioclim_grs.csv\")\n",
    "    df_i = df.set_index('gbifID')\n",
    "    media_df = df_i.merge(df_m,  left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d74b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_scraping():\n",
    "    ## foldername for the thumbnails\n",
    "    fold_n_thumb = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/thumbnails/'\n",
    "    fi_n = os.listdir(fold_n_thumb)\n",
    "    files = [os.path.splitext(filename)[0] for filename in os.listdir(fold_n_thumb)]\n",
    "    #fi_n.remove('.DS_Store') ## in case you have a mac - this might be necessary\n",
    "    \n",
    "    ## read out the already existing files in the folder...\n",
    "    media_df_nodupl = media_df[~media_df.index.duplicated(keep='first')]\n",
    "    list_indexes = media_df_nodupl.index\n",
    "    diff_li = list(set(list_indexes) - set(files))\n",
    "    \n",
    "    ## shuffle the list - this might be necessary since requests at the same api in a row might deny access\n",
    "    random.shuffle(diff_li)\n",
    "\n",
    "    ## request and store images in \"images\" folder\n",
    "    for i in range(0, 10000):\n",
    "        try:\n",
    "            r = requests.get(media_df_nodupl.loc[int(diff_li[i]),'identifier'], stream=True) #Get request on full_url\n",
    "            with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/images/{int(diff_li[i])}.jpg\", 'wb') as f: \n",
    "                r.raw.decode_content = True\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        time.sleep(random.uniform(0.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_croping_and_scaling():\n",
    "    ## get images from images folde\n",
    "    fold_n_im = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/images/'\n",
    "    fi_n = os.listdir(fold_n_im)\n",
    "    fi_n.remove('.DS_Store')\n",
    "\n",
    "    ## crop and scale images to thumnails folder\n",
    "    for i in range(len(fi_n)):\n",
    "        try:\n",
    "            image = Image.open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/images/{fi_n[i]}\")\n",
    "            image = crop_max_square(image).resize((300, 300))\n",
    "            image.save(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/thumbnails/{fi_n[i]}\") \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace92f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_max_square(pil_img):\n",
    "    return crop_center(pil_img, min(pil_img.size), min(pil_img.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(pil_img, crop_width, crop_height):\n",
    "    img_width, img_height = pil_img.size\n",
    "    return pil_img.crop(((img_width - crop_width) // 2,\n",
    "                         (img_height - crop_height) // 2,\n",
    "                         (img_width + crop_width) // 2,\n",
    "                         (img_height + crop_height) // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820cfe26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
