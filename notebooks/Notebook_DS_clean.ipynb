{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1eb890a",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c800ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1462ae",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - variables - functions - calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee261d21",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val_nam_list = ['cld', 'dtr', 'frs', 'pet', 'pre', 'tmn', 'tmp', 'tmx', 'vap', 'wet']\n",
    "fold_n = '/Users/davidschildberger/03_LeWagon_Datasets/CRU_raw_data_2021/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd4051",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_filename(feat_name):\n",
    "    fi_n = os.listdir(fold_n)\n",
    "    fi_n.remove('.DS_Store')\n",
    "    for i in fi_n: \n",
    "        if(feat_name in i) : \n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fdcc76",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def open_netcdf(fname):\n",
    "    with gzip.open((fold_n+fname), 'rb') as f:\n",
    "        tmp = tempfile.NamedTemporaryFile(delete=False)\n",
    "        shutil.copyfileobj(f, tmp)\n",
    "\n",
    "        f.close()\n",
    "        tmp.close()\n",
    "        \n",
    "        data = netCDF4.Dataset(tmp.name)\n",
    "        os.unlink(tmp.name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72ddc9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Bio 1 / Annual Mean Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059d81e6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_1(year):\n",
    "    val = 'tmp'\n",
    "    data = open_netcdf(get_filename(val))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    d = data.variables[val][year_in_month:year_in_month+12,:,:].data.mean(axis=0)\n",
    "    d[d > 99999] = np.nan\n",
    "    res = np.flip(d,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdcb45b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Bio 2 / Mean Diurnal Range (Mean of monthly (max temp - min temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a51712",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_2(year):\n",
    "    data_tmn = open_netcdf(get_filename('tmn'))\n",
    "    data_tmx = open_netcdf(get_filename('tmx'))\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_min = data_tmn.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_max = data_tmx.variables['tmx'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_min[t_min > 255] = np.nan\n",
    "    t_max[t_max > 255] = np.nan\n",
    "    d = t_max - t_min\n",
    "    d = d.mean(axis=0)\n",
    "    d[d > 99999] = np.nan\n",
    "    res = np.flip(d,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7505b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 3 / Isothermality (BIO2/BIO7) (×100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb43613",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_3(year):\n",
    "    val = bio_2(year)/bio_7(year)\n",
    "    val[val > 99999] = np.nan\n",
    "    res = np.around(val, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12bbb1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 4 / Temperature Seasonality (standard deviation ×100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e935a2b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_4(year):\n",
    "    data = open_netcdf(get_filename('tmp'))\n",
    "\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_mp = data.variables['tmp'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_mp[t_mp > 99999] = np.nan\n",
    "    res = np.std(t_mp, axis=0)\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646f7d3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 5 / Max Temperature of Warmest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c318138",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_5(year):\n",
    "    data = open_netcdf(get_filename('tmx'))\n",
    "\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_max = data.variables['tmx'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_max[t_max > 99999] = np.nan\n",
    "    res = np.max(t_max, axis=0)\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144a456",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 6 / Min Temperature of Coldest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb010b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_6(year):\n",
    "    data = open_netcdf(get_filename('tmn'))\n",
    "\n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    t_min = data.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    t_min[t_min > 99999] = np.nan\n",
    "    res = np.min(t_min, axis=0)\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903863e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 7 / Temperature Annual Range (BIO5-BIO6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23f868",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_7(year):\n",
    "    rang_temp = bio_5(1980)-bio_6(1980)\n",
    "    rang_temp[rang_temp > 99999] = np.nan\n",
    "    res = np.around(rang_temp, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a94e8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 8 / Mean Temperature of Wettest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb08f44",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_8(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24bbbfb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 9 / Mean Temperature of Driest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3eae4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_9(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c4d9b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO10 / Mean Temperature of Warmest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd7015",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_10(year):\n",
    "    data_wet = open_netcdf(get_filename('tmx'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmx'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d5ddb8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 11 / Mean Temperature of Coldest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b355e63",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_11(year):\n",
    "    data_wet = open_netcdf(get_filename('tmn'))\n",
    "    data_tmp = open_netcdf(get_filename('tmp'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.mean(data_tmp.variables['tmp'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c16cb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 12 / Annual Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7dde0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_12(year):\n",
    "    data_pre = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_pre.variables['pre'][year_in_month:year_in_month+12,:,:].data\n",
    "    temp_wet[temp_wet > 99999] = np.nan\n",
    "    temp_wet = np.sum(temp_wet, axis=0)\n",
    "    res = np.flip(temp_wet,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541fc61e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 13 / Precipitation of Wettest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61e798",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_13(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    max_ind = np.argmax(temp_wet, axis=0)\n",
    "        \n",
    "    res = np.choose(max_ind, data_tmp.variables['pre'][year_in_month:year_in_month+12,:,:].data)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab428407",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 14 / Precipitation of Driest Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03411860",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_14(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    min_ind = np.argmin(temp_wet, axis=0)\n",
    "        \n",
    "    res = np.choose(min_ind, data_tmp.variables['pre'][year_in_month:year_in_month+12,:,:].data)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746489f6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 15 / Precipitation Seasonality (Coefficient of Variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acab82ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_15(year):\n",
    "    val = 'pre'\n",
    "    data = open_netcdf(get_filename(val))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    d = data.variables[val][year_in_month:year_in_month+12,:,:].data\n",
    "    d[d > 99999] = np.nan\n",
    "    cv = lambda x: np.std(d, ddof=1, axis=0) / np.mean(d, axis=0) * 100\n",
    "    d = cv(d)\n",
    "    res = np.flip(d,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ccea80",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 16 / Precipitation of Wettest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8903ed85",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_16(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c69eb2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 17 / Precipitation of Driest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f12f8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_17(year):\n",
    "    data_wet = open_netcdf(get_filename('wet'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['wet'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a184e3fe",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO 18 / Precipitation of Warmest Quarter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc9b711",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_18(year):\n",
    "    data_wet = open_netcdf(get_filename('tmp'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmp'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    max_ind = np.argmax(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(max_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19319f8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## BIO19 / Precipitation of Coldest Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fd4a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def bio_19(year):\n",
    "    data_wet = open_netcdf(get_filename('tmn'))\n",
    "    data_tmp = open_netcdf(get_filename('pre'))\n",
    "    \n",
    "    year_in_month = (year-1901)*12\n",
    "    \n",
    "    temp_wet =  data_wet.variables['tmn'][year_in_month:year_in_month+12,:,:].data\n",
    "    \n",
    "    li_temp = []\n",
    "    for i in range(0,11,3):\n",
    "        li_temp.append(np.sum(temp_wet[i:i+3], axis=0))\n",
    "    li_temp = np.array(li_temp)\n",
    "    min_ind = np.argmin(li_temp, axis=0)\n",
    "    \n",
    "    li_q_t = []\n",
    "    for i in range(0,11,3):\n",
    "        li_q_t.append(np.sum(data_tmp.variables['pre'][year_in_month+i:year_in_month+i+3,:,:].data, axis=0))\n",
    "\n",
    "    li_q_t = np.array(li_q_t)\n",
    "    \n",
    "    res = np.choose(min_ind, li_q_t)\n",
    "    res[res > 99999] = np.nan\n",
    "    res = np.flip(res,0)\n",
    "    res = np.around(res, decimals=2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63b885",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - create and save files for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31319e05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_and_save_bioclim():\n",
    "    for i in range(120,121):\n",
    "        st = 1901+i\n",
    "        os.makedirs(f\"../raw_data/bioclim/{st}\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_1.csv\", \n",
    "                   bio_1(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_2.csv\", \n",
    "                   bio_2(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_3.csv\", \n",
    "                   bio_3(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_4.csv\", \n",
    "                   bio_4(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_5.csv\", \n",
    "                   bio_5(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_6.csv\", \n",
    "                   bio_6(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_7.csv\", \n",
    "                   bio_7(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_8.csv\", \n",
    "                   bio_8(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_9.csv\", \n",
    "                   bio_9(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_10.csv\", \n",
    "                   bio_10(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_11.csv\", \n",
    "                   bio_11(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_12.csv\", \n",
    "                   bio_12(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_13.csv\", \n",
    "                   bio_13(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_14.csv\", \n",
    "                   bio_14(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_15.csv\", \n",
    "                   bio_15(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_16.csv\", \n",
    "                   bio_16(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_17.csv\", \n",
    "                   bio_17(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_18.csv\", \n",
    "                   bio_18(st), delimiter=\",\")\n",
    "        np.savetxt(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{st}/bio_19.csv\", \n",
    "                   bio_19(st), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7614a958",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - read out all years and create big .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a52151",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_csv_store_npy():\n",
    "    all_dat = []\n",
    "    for j in range(1901,2022):\n",
    "        print(j)\n",
    "        path = f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim/{j}/\"\n",
    "        #fi_n = os.listdir(path)\n",
    "        my_data = []\n",
    "        for i in range(19):\n",
    "            my_data.append(np.loadtxt(path+f\"bio_{i+1}.csv\", delimiter=\",\"))\n",
    "        all_dat.append(my_data)\n",
    "        \n",
    "    with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim_np/Bioclim.npy\", 'wb') as f:\n",
    "        np.save(f, np.array(all_dat))\n",
    "    return np.array(all_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc0fcb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bioclim - Hist Clim for all exising lon/lat vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885cf33",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_all_climate_lon_lat():\n",
    "    \n",
    "    path = f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim_np/\"\n",
    "    filen = 'bioclim_upd.npy'\n",
    "    bioclim = np.load(path+filen)\n",
    "    \n",
    "    li_hist_df = []\n",
    "    for g in range(121):\n",
    "        li_clim = []\n",
    "        li_lon_lat_years = []\n",
    "        li_lon_lat = []\n",
    "        li_lon_lon = []\n",
    "        for i in range(360):\n",
    "            for j in range(720):\n",
    "                li_temp = []\n",
    "                for k in range(19):\n",
    "                    li_temp.append(bioclim[g,k,i,j])\n",
    "                li_lon_lat_years.append(f\"{g}\")\n",
    "                li_lon_lat.append(f\"{i}\")\n",
    "                li_lon_lon.append(f\"{j}\")\n",
    "                li_clim.append(li_temp)\n",
    "        aa = np.stack((np.array(li_lon_lat_years), np.array(li_lon_lat), np.array(li_lon_lon)))\n",
    "        aa = np.transpose(aa)\n",
    "        cc = np.array(li_clim)\n",
    "        uu = np.hstack((aa, cc))\n",
    "        xx = pd.DataFrame(uu)\n",
    "        xx = xx[xx[3].str.contains(\"nan\")==False]\n",
    "        li_hist_df.append(xx.to_numpy())\n",
    "    with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/world_history_bioclim_allLatLon_upd.npy\", 'wb') as f:\n",
    "        np.save(f, d)    \n",
    "    return np.array(li_hist_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2836c1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Soilgrid - for all exising lon/lat vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad570ef",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_all_climate_soil_grid_lon_lat():\n",
    "    path = f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/bioclim_np/\"\n",
    "    filen = 'bioclim_upd.npy'\n",
    "    bioclim = np.load(path+filen)\n",
    "    data = np.load(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/soil_data.npy\")\n",
    "    \n",
    "    li_clim = []\n",
    "    li_lon_lat = []\n",
    "    li_lon_lon = []\n",
    "    for i in range(360):\n",
    "        #print(i)\n",
    "        for j in range(720):\n",
    "            li_temp = []\n",
    "            for k in range(19):\n",
    "                li_temp.append(bioclim[0,k,i,j])\n",
    "            for u in range(60):\n",
    "                li_temp.append(data[k,i,j])\n",
    "            \n",
    "            li_lon_lat.append(f\"{i}\")\n",
    "            li_lon_lon.append(f\"{j}\")\n",
    "            li_clim.append(li_temp)\n",
    "                \n",
    "    aa = np.stack((np.array(li_lon_lat), np.array(li_lon_lon)))\n",
    "    aa = np.transpose(aa)\n",
    "    cc = np.array(li_clim)\n",
    "    uu = np.hstack((aa, cc))\n",
    "    xx = pd.DataFrame(uu)\n",
    "    xx = xx[xx[3].str.contains(\"nan\")==False]\n",
    "    xx.columns = [np.arange(0,81)]\n",
    "    xx = xx.drop(xx.columns[np.arange(2,21)],axis = 1)\n",
    "    xx.columns = [np.arange(0,62)]\n",
    "    with open(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/world_soilgrid_allLatLon_withzeros_upd.npy\", 'wb') as f:\n",
    "        np.save(f, xx)\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b24af1",
   "metadata": {},
   "source": [
    "# Bioclim - Hist Clim and Soil Data for all exising lon/lat vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_histclim_soilgrid_lon_lat():\n",
    "    path = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/'\n",
    "    file_c = 'world_history_bioclim_allLatLon_upd.npy'\n",
    "    file_s = 'world_soilgrid_allLatLon_withzeros_upd.npy'\n",
    "    cl_data = np.load(path+file_c, allow_pickle=True)\n",
    "    sg_data = np.load(path+file_s, allow_pickle=True)\n",
    "\n",
    "    np.concatenate((cl_data[0,:,:], sg_data), axis=1).shape\n",
    "\n",
    "    lit = []\n",
    "    for i in range(len(cl_data)):\n",
    "        lit.append(np.concatenate((cl_data[i,:,:], sg_data[:,2:]), axis=1))\n",
    "    lit = np.array(lit)\n",
    "\n",
    "    with open(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/clim_hist_soil_overall.npy\", 'wb') as f:\n",
    "        np.save(f, lit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b089dbd",
   "metadata": {},
   "source": [
    "# Plants - Retrieve Bioclim and Soilgrid Data for plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6a63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b81307be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Image scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829f57e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_urls_to_scrap():\n",
    "    ## get plant - multimedia data\n",
    "    df_m = pd.read_csv('/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/multimedia.txt', sep='\\t', index_col='gbifID')\n",
    "    df_m = df_m[['identifier']]\n",
    "    ## get plant - info\n",
    "    df_i = pd.read_csv(\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/data_inkl_bioclim_grs.csv\")\n",
    "    df_i = df.set_index('gbifID')\n",
    "    media_df = df_i.merge(df_m,  left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9adee03",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def img_scraping():\n",
    "    ## foldername for the thumbnails\n",
    "    fold_n_thumb = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/thumbnails/'\n",
    "    fi_n = os.listdir(fold_n_thumb)\n",
    "    files = [os.path.splitext(filename)[0] for filename in os.listdir(fold_n_thumb)]\n",
    "    #fi_n.remove('.DS_Store') ## in case you have a mac - this might be necessary\n",
    "    \n",
    "    ## read out the already existing files in the folder...\n",
    "    media_df_nodupl = media_df[~media_df.index.duplicated(keep='first')]\n",
    "    list_indexes = media_df_nodupl.index\n",
    "    diff_li = list(set(list_indexes) - set(files))\n",
    "    \n",
    "    ## shuffle the list - this might be necessary since requests at the same api in a row might deny access\n",
    "    random.shuffle(diff_li)\n",
    "\n",
    "    ## request and store images in \"images\" folder\n",
    "    for i in range(0, 10000):\n",
    "        try:\n",
    "            r = requests.get(media_df_nodupl.loc[int(diff_li[i]),'identifier'], stream=True) #Get request on full_url\n",
    "            with open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/images/{int(diff_li[i])}.jpg\", 'wb') as f: \n",
    "                r.raw.decode_content = True\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        time.sleep(random.uniform(0.5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d6286a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def img_croping_and_scaling():\n",
    "    ## get images from images folde\n",
    "    fold_n_im = '/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/images/'\n",
    "    fi_n = os.listdir(fold_n_im)\n",
    "    fi_n.remove('.DS_Store')\n",
    "\n",
    "    ## crop and scale images to thumnails folder\n",
    "    for i in range(len(fi_n)):\n",
    "        try:\n",
    "            image = Image.open(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/images/{fi_n[i]}\")\n",
    "            image = crop_max_square(image).resize((300, 300))\n",
    "            image.save(f\"/Users/davidschildberger/code/dadavie/planetary_garden/raw_data/thumbnails/{fi_n[i]}\") \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079d1fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def crop_max_square(pil_img):\n",
    "    return crop_center(pil_img, min(pil_img.size), min(pil_img.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbb0605",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def crop_center(pil_img, crop_width, crop_height):\n",
    "    img_width, img_height = pil_img.size\n",
    "    return pil_img.crop(((img_width - crop_width) // 2,\n",
    "                         (img_height - crop_height) // 2,\n",
    "                         (img_width + crop_width) // 2,\n",
    "                         (img_height + crop_height) // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04daad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
